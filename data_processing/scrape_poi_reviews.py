"""
Script ƒë·ªÉ t√¨m ki·∫øm POI b·∫±ng Google Text Search API v√† scrape reviews b·∫±ng Playwright
- T√¨m POI b·∫±ng Google Places API (Text Search)
- L·ªçc POI c√≥ s·ªë l∆∞·ª£ng reviews > 100
- Scrape reviews t·ª´ Google Maps b·∫±ng Playwright (v·ªõi anti-detection)
- Xu·∫•t ra file reviews.csv v·ªõi c√°c c·ªôt: placeID, reviews
"""

import os
import time
import csv
import json
import requests
import random
import urllib3
from dotenv import load_dotenv
from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeoutError
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

# Disable SSL warnings v√† verification (ƒë·ªÉ x·ª≠ l√Ω l·ªói certificate tr√™n Windows)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# T·∫°o session v·ªõi SSL verification disabled
def create_requests_session():
    """
    T·∫°o requests session v·ªõi SSL verification disabled ƒë·ªÉ x·ª≠ l√Ω l·ªói certificate tr√™n Windows
    """
    session = requests.Session()
    session.verify = False  # Disable SSL verification
    return session

# Load bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()

# Google Places API Key
GOOGLE_PLACES_API_KEY = os.getenv('GOOGLE_PLACES_API_KEY', '')

if not GOOGLE_PLACES_API_KEY:
    print("‚ö†Ô∏è  C·∫¢NH B√ÅO: GOOGLE_PLACES_API_KEY ch∆∞a ƒë∆∞·ª£c set trong bi·∫øn m√¥i tr∆∞·ªùng!")
    print("   H√£y set: export GOOGLE_PLACES_API_KEY='your_key'")
    exit(1)
else:
    print(f"‚úÖ GOOGLE_PLACES_API_KEY ƒë√£ ƒë∆∞·ª£c set (ƒë·ªô d√†i: {len(GOOGLE_PLACES_API_KEY)} k√Ω t·ª±)")

def search_pois_by_text(query: str, location: str = None, min_results: int = 65, max_results: int = 200, existing_place_ids: set = None):
    """
    T√¨m ki·∫øm POI b·∫±ng Google Places API (Text Search) v·ªõi pagination
    
    Args:
        query: T·ª´ kh√≥a t√¨m ki·∫øm (v√≠ d·ª•: "restaurants in Ho Chi Minh City")
        location: V·ªã tr√≠ t√¨m ki·∫øm (optional, format: "lat,lng")
        min_results: S·ªë l∆∞·ª£ng POI t·ªëi thi·ªÉu c·∫ßn l·∫•y (m·∫∑c ƒë·ªãnh 65)
        max_results: S·ªë l∆∞·ª£ng k·∫øt qu·∫£ t·ªëi ƒëa mu·ªën l·∫•y (m·∫∑c ƒë·ªãnh 200)
    
    Returns:
        List c√°c POI v·ªõi place_id, name, user_rating_total
    """
    url = "https://places.googleapis.com/v1/places:searchText"
    
    headers = {
        'Content-Type': 'application/json',
        'X-Goog-Api-Key': GOOGLE_PLACES_API_KEY,
        'X-Goog-FieldMask': 'places.id,places.displayName,places.userRatingCount,nextPageToken'
    }
    
    # T·∫°o request body
    body = {
        "textQuery": query,
        "maxResultCount": 20  # T·ªëi ƒëa 20 k·∫øt qu·∫£ m·ªói request
    }
    
    if location:
        # Parse location n·∫øu c√≥
        try:
            lat, lng = map(float, location.split(','))
            body["locationBias"] = {
                "circle": {
                    "center": {
                        "latitude": lat,
                        "longitude": lng
                    },
                    "radius": 15000.0  # TƒÉng l√™n 15km radius ƒë·ªÉ t√¨m ƒë∆∞·ª£c nhi·ªÅu POI h∆°n
                }
            }
        except:
            pass
    
    # T·∫°o session v·ªõi SSL verification disabled
    session = create_requests_session()
    
    all_pois = []
    all_place_ids = existing_place_ids.copy() if existing_place_ids else set()
    next_page_token = None
    page_count = 0
    
    try:
        while True:
            page_count += 1
            print(f"\n{'‚îÄ'*60}")
            print(f"üìÑ Trang {page_count} | ƒê√£ l·∫•y: {len(all_pois)}/{max_results} POI")
            print(f"{'‚îÄ'*60}")
            
            # N·∫øu c√≥ nextPageToken t·ª´ l·∫ßn tr∆∞·ªõc, th√™m v√†o body
            if next_page_token:
                body["pageToken"] = next_page_token
            
            # G·ªçi API v·ªõi session ƒë√£ disable SSL verification
            response = session.post(url, headers=headers, json=body, timeout=10)
            
            if response.status_code != 200:
                print(f"‚ùå L·ªói API: HTTP {response.status_code}")
                print(f"   Chi ti·∫øt: {response.text[:200]}")
                break
            
            data = response.json()
            places = data.get('places', [])
            next_page_token = data.get('nextPageToken')
            
            print(f"   üì• Nh·∫≠n ƒë∆∞·ª£c {len(places)} POI t·ª´ API")
            
            # X·ª≠ l√Ω t·ª´ng place
            valid_count = 0
            skipped_count = 0
            for place in places:
                place_id = place.get('id', '')
                name = place.get('displayName', {}).get('text', '') if isinstance(place.get('displayName'), dict) else place.get('displayName', '')
                user_rating_count = place.get('userRatingCount', 0)
                
                # Ch·ªâ l·∫•y POI c√≥ s·ªë l∆∞·ª£ng reviews > 100 v√† ch∆∞a c√≥ trong danh s√°ch
                if user_rating_count and user_rating_count > 100 and place_id not in all_place_ids:
                    all_pois.append({
                        'place_id': place_id,
                        'name': name,
                        'user_rating_total': user_rating_count
                    })
                    all_place_ids.add(place_id)  # Th√™m v√†o set ƒë·ªÉ tr√°nh tr√πng l·∫∑p
                    valid_count += 1
                    print(f"   ‚úÖ [{len(all_pois):3d}] {name[:50]:<50} | {user_rating_count:>6} reviews")
                else:
                    skipped_count += 1
                    if skipped_count <= 3:  # Ch·ªâ hi·ªÉn th·ªã 3 POI ƒë·∫ßu ti√™n b·ªã b·ªè qua
                        print(f"   ‚è≠Ô∏è  [{skipped_count:3d}] {name[:50]:<50} | {user_rating_count:>6} reviews (b·ªè qua)")
            
            if skipped_count > 3:
                print(f"   ‚è≠Ô∏è  ... v√† {skipped_count - 3} POI kh√°c b·ªã b·ªè qua (< 100 reviews)")
            
            print(f"   üìä Trang n√†y: {valid_count} h·ª£p l·ªá, {skipped_count} b·ªè qua")
            
            # Ki·ªÉm tra ƒëi·ªÅu ki·ªán d·ª´ng
            if not next_page_token:
                print(f"\n   ‚èπÔ∏è  Kh√¥ng c√≤n trang ti·∫øp theo")
                if len(all_pois) < min_results:
                    print(f"   ‚ö†Ô∏è  C·∫£nh b√°o: Ch·ªâ l·∫•y ƒë∆∞·ª£c {len(all_pois)}/{min_results} POI (thi·∫øu {min_results - len(all_pois)} POI)")
                break
            
            if len(all_pois) >= max_results:
                print(f"\n   ‚úÖ ƒê√£ ƒë·∫°t gi·ªõi h·∫°n {max_results} POI")
                break
            
            # N·∫øu ƒë√£ ƒë·ªß min_results nh∆∞ng ch∆∞a ƒë·∫°t max_results, v·∫´n ti·∫øp t·ª•c ƒë·ªÉ l·∫•y th√™m
            if len(all_pois) >= min_results and len(all_pois) < max_results:
                remaining = max_results - len(all_pois)
                print(f"   üìà ƒê√£ ƒë·ªß {min_results} POI, ti·∫øp t·ª•c l·∫•y th√™m {remaining} POI...")
            
            # ƒê·ª£i m·ªôt ch√∫t tr∆∞·ªõc khi g·ªçi request ti·∫øp theo (tr√°nh rate limit)
            print(f"   ‚è≥ ƒê·ª£i 2 gi√¢y tr∆∞·ªõc khi l·∫•y trang ti·∫øp theo...")
            time.sleep(2)
            
            # X√≥a pageToken kh·ªèi body ƒë·ªÉ tr√°nh l·ªói n·∫øu kh√¥ng c√≥ nextPageToken
            if 'pageToken' in body:
                del body['pageToken']
        
        print(f"\n{'‚ïê'*60}")
        print(f"‚úÖ Ho√†n t·∫•t: {len(all_pois)} POI h·ª£p l·ªá t·ª´ {page_count} trang")
        print(f"{'‚ïê'*60}\n")
        return all_pois[:max_results]  # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng k·∫øt qu·∫£
        
    except Exception as e:
        print(f"‚ùå L·ªói khi g·ªçi API: {e}")
        import traceback
        traceback.print_exc()
        return all_pois  # Tr·∫£ v·ªÅ nh·ªØng g√¨ ƒë√£ l·∫•y ƒë∆∞·ª£c

# User agents pool ƒë·ªÉ randomize
USER_AGENTS = [
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
]

# Viewport sizes ƒë·ªÉ randomize
VIEWPORT_SIZES = [
    {"width": 1920, "height": 1080},
    {"width": 1366, "height": 768},
    {"width": 1536, "height": 864},
    {"width": 1440, "height": 900},
    {"width": 1280, "height": 720},
]

def human_delay(min_seconds=0.5, max_seconds=2.0):
    """Random delay ƒë·ªÉ m√¥ ph·ªèng h√†nh vi con ng∆∞·ªùi"""
    delay = random.uniform(min_seconds, max_seconds)
    time.sleep(delay)

def human_scroll(page, container=None, steps=3):
    """Scroll gi·ªëng con ng∆∞·ªùi v·ªõi random pauses"""
    if container:
        # Scroll trong container
        for i in range(steps):
            scroll_amount = random.randint(200, 500)
            try:
                page.evaluate(f"""
                    (container) => {{
                        container.scrollTop += {scroll_amount};
                    }}
                """, container.element_handle())
            except:
                # Fallback: scroll page
                page.mouse.wheel(0, scroll_amount)
            human_delay(0.3, 0.8)
    else:
        # Scroll trang
        for i in range(steps):
            scroll_amount = random.randint(300, 600)
            page.mouse.wheel(0, scroll_amount)
            human_delay(0.4, 1.0)

def setup_playwright_browser(playwright):
    """
    Thi·∫øt l·∫≠p Playwright Browser v·ªõi anti-detection
    """
    try:
        # Random user agent v√† viewport
        user_agent = random.choice(USER_AGENTS)
        viewport = random.choice(VIEWPORT_SIZES)
        
        # Launch browser v·ªõi stealth mode v√† th√™m args ƒë·ªÉ tr√°nh detection
        browser = playwright.chromium.launch(
            headless=True,  # C√≥ th·ªÉ ƒë·ªïi th√†nh False ƒë·ªÉ debug
            args=[
                '--disable-blink-features=AutomationControlled',
                '--disable-dev-shm-usage',
                '--no-sandbox',
                '--disable-setuid-sandbox',
                '--disable-web-security',
                '--disable-features=IsolateOrigins,site-per-process',
                '--disable-infobars',
                '--disable-notifications',
                '--disable-popup-blocking',
                '--start-maximized',
                '--disable-extensions',
                '--disable-plugins-discovery',
                '--disable-default-apps',
            ]
        )
        
        # T·∫°o context v·ªõi anti-detection settings
        context = browser.new_context(
            viewport=viewport,
            user_agent=user_agent,
            locale='en-US',
            timezone_id='America/New_York',
            permissions=['geolocation'],
            geolocation={'latitude': 10.8231, 'longitude': 106.6297},  # HCM coordinates
            color_scheme='light',
            # Th√™m extra HTTP headers
            extra_http_headers={
                'Accept-Language': 'en-US,en;q=0.9',
                'Accept-Encoding': 'gzip, deflate, br',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
            }
        )
        
        # Inject stealth scripts ƒë·ªÉ ·∫©n automation (n√¢ng cao)
        context.add_init_script("""
            // Override navigator.webdriver
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
            
            // Override chrome object
            window.chrome = {
                runtime: {},
                loadTimes: function() {},
                csi: function() {},
                app: {}
            };
            
            // Override permissions
            const originalQuery = window.navigator.permissions.query;
            window.navigator.permissions.query = (parameters) => (
                parameters.name === 'notifications' ?
                    Promise.resolve({ state: Notification.permission }) :
                    originalQuery(parameters)
            );
            
            // Override plugins
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5]
            });
            
            // Override languages
            Object.defineProperty(navigator, 'languages', {
                get: () => ['en-US', 'en']
            });
            
            // Override platform
            Object.defineProperty(navigator, 'platform', {
                get: () => 'MacIntel'
            });
            
            // Override hardwareConcurrency
            Object.defineProperty(navigator, 'hardwareConcurrency', {
                get: () => 8
            });
            
            // Override deviceMemory
            Object.defineProperty(navigator, 'deviceMemory', {
                get: () => 8
            });
            
            // Override getBattery
            if (navigator.getBattery) {
                navigator.getBattery = () => Promise.resolve({
                    charging: true,
                    chargingTime: 0,
                    dischargingTime: Infinity,
                    level: 1
                });
            }
            
            // Override connection
            Object.defineProperty(navigator, 'connection', {
                get: () => ({
                    effectiveType: '4g',
                    rtt: 50,
                    downlink: 10,
                    saveData: false
                })
            });
        """)
        
        page = context.new_page()
        
        return browser, context, page
        
    except Exception as e:
        print(f"‚ùå L·ªói khi kh·ªüi t·∫°o Playwright Browser: {e}")
        print("   G·ª£i √Ω: Ch·∫°y 'playwright install chromium' ƒë·ªÉ c√†i ƒë·∫∑t browser")
        return None, None, None

def scrape_reviews_from_google_maps(place_id: str, page, min_reviews: int = 90, max_reviews: int = 120):
    """
    Scrape reviews t·ª´ Google Maps b·∫±ng Playwright v·ªõi anti-detection
    
    Args:
        place_id: Place ID c·ªßa POI
        page: Playwright Page instance
        min_reviews: S·ªë l∆∞·ª£ng reviews t·ªëi thi·ªÉu c·∫ßn l·∫•y (m·∫∑c ƒë·ªãnh 90)
        max_reviews: S·ªë l∆∞·ª£ng reviews t·ªëi ƒëa c·∫ßn l·∫•y (m·∫∑c ƒë·ªãnh 120)
    
    Returns:
        List c√°c review text
    """
    # URL Google Maps cho place_id - s·ª≠ d·ª•ng format ƒë√∫ng
    url = f"https://www.google.com/maps/place/?q=place_id:{place_id}"
    # Ho·∫∑c c√≥ th·ªÉ th·ª≠ format kh√°c n·∫øu kh√¥ng ho·∫°t ƒë·ªông:
    # url = f"https://www.google.com/maps/search/?api=1&query=place_id:{place_id}"
    
    reviews = []
    
    try:
        # Navigate v·ªõi human-like behavior v√† retry logic
        max_retries = 3
        retry_count = 0
        navigation_success = False
        
        while retry_count < max_retries and not navigation_success:
            try:
                # TƒÉng timeout v√† d√πng 'domcontentloaded' thay v√¨ 'networkidle' ƒë·ªÉ nhanh h∆°n
                page.goto(url, wait_until='domcontentloaded', timeout=60000)
                navigation_success = True
                human_delay(3.0, 5.0)  # ƒê·ª£i trang load ho√†n to√†n
            except PlaywrightTimeoutError:
                retry_count += 1
                if retry_count < max_retries:
                    print(f"      ‚ö†Ô∏è  Timeout l·∫ßn {retry_count}, retry...")
                    human_delay(2.0, 4.0)  # ƒê·ª£i tr∆∞·ªõc khi retry
                else:
                    print(f"      ‚ùå Timeout sau {max_retries} l·∫ßn th·ª≠")
                    return []
        
        if not navigation_success:
            return []
        
        # Random mouse movement ƒë·ªÉ m√¥ ph·ªèng con ng∆∞·ªùi
        page.mouse.move(random.randint(100, 500), random.randint(100, 500))
        human_delay(0.5, 1.0)
        
        # ƒê·ª£i th√™m ƒë·ªÉ ƒë·∫£m b·∫£o trang ƒë√£ load ƒë·∫ßy ƒë·ªß
        try:
            page.wait_for_load_state('networkidle', timeout=10000)
        except:
            pass  # B·ªè qua n·∫øu timeout, trang c√≥ th·ªÉ ƒë√£ load ƒë·ªß
        
        try:
            # B∆∞·ªõc 1: T√¨m v√† click v√†o button "Reviews" ho·∫∑c tab "Reviews"
            review_button_selectors = [
                "button[data-value='Reviews']",
                "button:has-text('Reviews')",
                "button[aria-label*='Review']",
                "//button[contains(text(), 'Reviews')]",
                "//span[contains(text(), 'Reviews')]/ancestor::button",
            ]
            
            review_button_clicked = False
            for selector in review_button_selectors:
                try:
                    if selector.startswith("//"):
                        button = page.locator(selector).first
                    else:
                        button = page.locator(selector).first
                    
                    if button.is_visible(timeout=2000):
                        # Human-like click v·ªõi mouse movement
                        box = button.bounding_box()
                        if box:
                            # Move mouse ƒë·∫øn button tr∆∞·ªõc khi click
                            page.mouse.move(box['x'] + box['width']/2, box['y'] + box['height']/2)
                            human_delay(0.2, 0.5)
                            button.click(timeout=5000)
                            review_button_clicked = True
                            human_delay(2.0, 3.5)  # ƒê·ª£i ph·∫ßn reviews load
                            break
                except:
                    continue
            
            # B∆∞·ªõc 2: Scroll xu·ªëng ƒë·ªÉ t√¨m ph·∫ßn reviews n·∫øu ch∆∞a click ƒë∆∞·ª£c
            if not review_button_clicked:
                human_scroll(page, steps=3)
                human_delay(1.0, 2.0)
            
            # B∆∞·ªõc 3: T√¨m ph·∫ßn t·ª≠ feed ch·ª©a reviews (role="feed" ho·∫∑c aria-label li√™n quan ƒë·∫øn reviews)
            review_feed = None
            
            # Th·ª≠ t√¨m theo role="feed" tr∆∞·ªõc (c√°ch t·ªët nh·∫•t)
            try:
                feed_elements = page.locator('[role="feed"]').all()
                for feed in feed_elements:
                    if feed.is_visible(timeout=1000):
                        # Ki·ªÉm tra xem c√≥ li√™n quan ƒë·∫øn reviews kh√¥ng
                        aria_label = feed.get_attribute('aria-label') or ''
                        if 'review' in aria_label.lower() or 'ƒë√°nh gi√°' in aria_label.lower() or aria_label == '':
                            review_feed = feed
                            break
            except:
                pass
            
            # N·∫øu kh√¥ng t√¨m th·∫•y, th·ª≠ t√¨m theo aria-label
            if not review_feed:
                try:
                    feed_selectors = [
                        '[aria-label*="Review"]',
                        '[aria-label*="review"]',
                        '[aria-label*="ƒê√°nh gi√°"]',
                        '[aria-label*="ƒë√°nh gi√°"]',
                        'div[role="feed"]',
                    ]
                    for selector in feed_selectors:
                        try:
                            feeds = page.locator(selector).all()
                            for feed in feeds:
                                if feed.is_visible(timeout=1000):
                                    review_feed = feed
                                    break
                            if review_feed:
                                break
                        except:
                            continue
                except:
                    pass
            
            # Fallback: T√¨m container reviews truy·ªÅn th·ªëng
            if not review_feed:
                review_container_selectors = [
                    "div.m6QErb[aria-label*='Review']",
                    "div[data-section-id='reviews']",
                    "div.m6QErb",
                ]
                
                for selector in review_container_selectors:
                    try:
                        containers = page.locator(selector).all()
                        for container in containers:
                            if container.is_visible(timeout=1000):
                                review_feed = container
                                break
                        if review_feed:
                            break
                    except:
                        continue
            
            # B∆∞·ªõc 4: Scroll trong ph·∫ßn reviews feed ƒë·ªÉ load th√™m reviews
            scroll_attempts = 0
            max_scroll_attempts = 200  # TƒÉng l√™n 200 l·∫ßn scroll ƒë·ªÉ l·∫•y nhi·ªÅu reviews h∆°n
            last_review_count = 0
            no_change_count = 0
            min_scrolls_before_stop = 50  # Ph·∫£i scroll √≠t nh·∫•t 50 l·∫ßn tr∆∞·ªõc khi c√≥ th·ªÉ d·ª´ng
            consecutive_no_change_threshold = 15  # TƒÉng threshold l√™n 15 l·∫ßn kh√¥ng thay ƒë·ªïi
            
            while scroll_attempts < max_scroll_attempts and len(reviews) < max_reviews:
                # D·ª´ng ngay khi ƒë·∫°t max_reviews
                if len(reviews) >= max_reviews:
                    break
                scroll_attempts += 1
                
                # Human-like scroll v·ªõi random delay
                if review_feed:
                    # Scroll trong feed element b·∫±ng JavaScript
                    try:
                        scroll_amount = random.randint(500, 1000)  # TƒÉng scroll amount ƒë·ªÉ scroll xa h∆°n
                        # D√πng page.evaluate() ƒë·ªÉ scroll ph·∫ßn t·ª≠ feed
                        page.evaluate("""
                            (feedElement, scrollAmount) => {
                                if (feedElement) {
                                    const beforeScroll = feedElement.scrollTop;
                                    // Scroll xu·ªëng
                                    feedElement.scrollTop += scrollAmount;
                                    
                                    // N·∫øu scroll kh√¥ng thay ƒë·ªïi (ƒë√£ ƒë·∫øn cu·ªëi), th·ª≠ scroll ƒë·∫øn cu·ªëi c√πng
                                    if (feedElement.scrollTop === beforeScroll) {
                                        feedElement.scrollTop = feedElement.scrollHeight;
                                    }
                                    
                                    // Ho·∫∑c scroll ƒë·∫øn cu·ªëi n·∫øu g·∫ßn cu·ªëi (90%)
                                    const maxScroll = feedElement.scrollHeight - feedElement.clientHeight;
                                    if (feedElement.scrollTop + scrollAmount >= maxScroll * 0.85) {
                                        feedElement.scrollTop = feedElement.scrollHeight;
                                    }
                                }
                            }
                        """, review_feed.element_handle(), scroll_amount)
                    except Exception as e:
                        # Fallback: scroll page
                        try:
                            page.mouse.wheel(0, random.randint(500, 900))
                        except:
                            pass
                else:
                    # Scroll trang n·∫øu kh√¥ng t√¨m th·∫•y feed
                    human_scroll(page, steps=random.randint(2, 4))
                
                # ƒê·ª£i ƒë·ªÉ reviews m·ªõi load (tƒÉng delay)
                human_delay(2.0, 4.0)  # TƒÉng delay l√™n 2-4 gi√¢y
                
                # Th·ªânh tho·∫£ng scroll th√™m m·ªôt ch√∫t ƒë·ªÉ trigger lazy loading
                if scroll_attempts % 5 == 0:
                    try:
                        if review_feed:
                            page.evaluate("""
                                (feedElement) => {
                                    if (feedElement) {
                                        feedElement.scrollTop += 100;
                                        setTimeout(() => {
                                            feedElement.scrollTop -= 50;
                                        }, 200);
                                    }
                                }
                            """, review_feed.element_handle())
                        human_delay(0.5, 1.0)
                    except:
                        pass
                
                # T√¨m v√† l·∫•y reviews sau m·ªói l·∫ßn scroll
                review_texts = set()
                
                # C√°c selector cho Google Maps reviews (c·∫≠p nh·∫≠t v·ªõi nhi·ªÅu selector h∆°n)
                selectors = [
                    "span.wiI7pd",  # Selector ch√≠nh
                    "div.MyEned span.wiI7pd",
                    "div.jftiEf span.wiI7pd",
                    "div[data-review-id] span.wiI7pd",
                    "span[data-review-id] span.wiI7pd",
                    "div.MyEned",
                    # Th√™m c√°c selector m·ªõi
                    "span[jsaction] span.wiI7pd",
                    "div[data-review-id]",
                    "span[data-review-id]",
                    "div[aria-label*='review'] span",
                    "div[aria-label*='Review'] span",
                    # Selector cho reviews d·∫°ng text
                    "div.jftiEf",
                    "div[class*='MyEned']",
                ]
                
                for selector in selectors:
                    try:
                        elements = page.locator(selector).all()
                        for elem in elements:
                            try:
                                # Th·ª≠ l·∫•y text v·ªõi timeout d√†i h∆°n
                                if elem.is_visible(timeout=1000):
                                    text = elem.inner_text(timeout=1000).strip()
                                    
                                    # L·ªçc text h·ª£p l·ªá (gi·∫£m ƒë·ªô d√†i t·ªëi thi·ªÉu xu·ªëng 10 k√Ω t·ª±)
                                    if (text and 
                                        len(text) > 10 and 
                                        len(text) < 5000 and
                                        not text.isdigit() and
                                        not text.startswith('‚òÖ') and
                                        ':' not in text[:15] and
                                        'See more' not in text.lower() and
                                        'Show more' not in text.lower() and
                                        'Helpful' not in text and
                                        'Translate' not in text and
                                        'Read more' not in text.lower() and
                                        'Less' not in text[:10] and
                                        'Reply' not in text[:10]):
                                        review_texts.add(text)
                            except:
                                continue
                    except:
                        continue
                
                # Th·ª≠ expand "See more" trong c√°c reviews ƒë√£ c√≥
                if scroll_attempts % 10 == 0:  # M·ªói 10 l·∫ßn scroll, th·ª≠ expand m·ªôt l·∫ßn
                    try:
                        see_more_in_review = page.locator("button:has-text('See more'), button:has-text('Show more'), span:has-text('See more')").all()
                        for btn in see_more_in_review[:5]:  # Ch·ªâ expand 5 c√°i ƒë·∫ßu ti√™n
                            try:
                                if btn.is_visible(timeout=1000):
                                    btn.click(timeout=2000)
                                    human_delay(0.5, 1.0)
                            except:
                                continue
                    except:
                        pass
                
                # C·∫≠p nh·∫≠t reviews
                current_count = len(review_texts)
                if current_count > last_review_count:
                    last_review_count = current_count
                    no_change_count = 0  # Reset counter khi c√≥ reviews m·ªõi
                else:
                    no_change_count += 1
                    # Ch·ªâ d·ª´ng n·∫øu:
                    # 1. ƒê√£ ƒë·∫°t t·ªëi thi·ªÉu min_reviews V√Ä kh√¥ng c√≥ thay ƒë·ªïi trong threshold l·∫ßn li√™n ti·∫øp
                    # 2. Ho·∫∑c ƒë√£ ƒë·∫°t max_reviews
                    if len(reviews) >= max_reviews:
                        break
                    
                    if len(reviews) >= min_reviews and scroll_attempts >= min_scrolls_before_stop and no_change_count >= consecutive_no_change_threshold:
                        # Th·ª≠ scroll ƒë·∫øn cu·ªëi c√πng m·ªôt l·∫ßn n·ªØa tr∆∞·ªõc khi d·ª´ng (n·∫øu ch∆∞a ƒë·∫°t max)
                        if len(reviews) < max_reviews:
                            try:
                                if review_feed:
                                    page.evaluate("""
                                        (feedElement) => {
                                            if (feedElement) {
                                                feedElement.scrollTop = feedElement.scrollHeight;
                                            }
                                        }
                                    """, review_feed.element_handle())
                                    human_delay(3.0, 5.0)  # ƒê·ª£i l√¢u h∆°n ƒë·ªÉ load reviews cu·ªëi c√πng
                            except:
                                pass
                        break
                
                # C·∫≠p nh·∫≠t danh s√°ch reviews
                reviews = list(review_texts)
            
            # B∆∞·ªõc 5: Th·ª≠ click "See more" ho·∫∑c "Show more reviews" n·∫øu c√≥
            try:
                see_more_selectors = [
                    "button:has-text('See more')",
                    "button:has-text('Show more')",
                    "//button[contains(text(), 'See more')]",
                    "//button[contains(text(), 'Show more')]",
                    "//button[@aria-label and contains(@aria-label, 'more')]",
                ]
                
                for selector in see_more_selectors:
                    try:
                        if selector.startswith("//"):
                            button = page.locator(selector).first
                        else:
                            button = page.locator(selector).first
                        
                        if button.is_visible(timeout=2000):
                            # Human-like click
                            box = button.bounding_box()
                            if box:
                                page.mouse.move(box['x'] + box['width']/2, box['y'] + box['height']/2)
                                human_delay(0.2, 0.5)
                                button.click(timeout=5000)
                                human_delay(2.0, 3.0)
                                
                                # Scroll th√™m sau khi click
                                if review_feed:
                                    for i in range(10):  # TƒÉng s·ªë l·∫ßn scroll sau khi click
                                        try:
                                            scroll_amount = random.randint(300, 800)
                                            page.evaluate("""
                                                (feedElement, scrollAmount) => {
                                                    if (feedElement) {
                                                        feedElement.scrollTop += scrollAmount;
                                                    }
                                                }
                                            """, review_feed.element_handle(), scroll_amount)
                                            human_delay(0.5, 1.2)
                                        except:
                                            page.mouse.wheel(0, random.randint(400, 700))
                                            human_delay(0.6, 1.3)
                                else:
                                    human_scroll(page, steps=10)
                                
                                # L·∫•y l·∫°i reviews sau khi click
                                review_texts = set()
                                for selector in selectors:
                                    try:
                                        elements = page.locator(selector).all()
                                        for elem in elements:
                                            try:
                                                text = elem.inner_text(timeout=500).strip() if elem.is_visible(timeout=500) else ""
                                                if (text and 
                                                    len(text) > 15 and 
                                                    len(text) < 5000 and
                                                    not text.isdigit() and
                                                    not text.startswith('‚òÖ') and
                                                    ':' not in text[:15] and
                                                    'See more' not in text and
                                                    'Show more' not in text and
                                                    'Helpful' not in text and
                                                    'Translate' not in text):
                                                    review_texts.add(text)
                                            except:
                                                continue
                                    except:
                                        continue
                                
                                reviews = list(review_texts)
                                break
                    except:
                        continue
            except:
                pass
            
            # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng reviews (t·ªëi ƒëa max_reviews)
            reviews = reviews[:max_reviews]
            
            # Ki·ªÉm tra xem c√≥ ƒë·ªß min_reviews kh√¥ng
            if len(reviews) < min_reviews:
                # N·∫øu ch∆∞a ƒë·ªß, th·ª≠ scroll th√™m m·ªôt l·∫ßn n·ªØa
                try:
                    if review_feed:
                        page.evaluate("""
                            (feedElement) => {
                                if (feedElement) {
                                    feedElement.scrollTop = feedElement.scrollHeight;
                                }
                            }
                        """, review_feed.element_handle())
                        human_delay(3.0, 5.0)
                        # L·∫•y l·∫°i reviews m·ªôt l·∫ßn n·ªØa
                        review_texts = set()
                        for selector in selectors:
                            try:
                                elements = page.locator(selector).all()
                                for elem in elements:
                                    try:
                                        if elem.is_visible(timeout=1000):
                                            text = elem.inner_text(timeout=1000).strip()
                                            if (text and 
                                                len(text) > 10 and 
                                                len(text) < 5000 and
                                                not text.isdigit() and
                                                not text.startswith('‚òÖ') and
                                                ':' not in text[:15] and
                                                'See more' not in text.lower() and
                                                'Show more' not in text.lower() and
                                                'Helpful' not in text and
                                                'Translate' not in text and
                                                'Read more' not in text.lower() and
                                                'Less' not in text[:10] and
                                                'Reply' not in text[:10]):
                                                review_texts.add(text)
                                    except:
                                        continue
                            except:
                                continue
                        reviews = list(review_texts)[:max_reviews]
                except:
                    pass
            
        except PlaywrightTimeoutError:
            print(f"      ‚ö†Ô∏è  Timeout khi ƒë·ª£i reviews load")
        except Exception as e:
            print(f"      ‚ö†Ô∏è  L·ªói: {str(e)[:100]}")
        
    except Exception as e:
        print(f"      ‚ùå L·ªói: {str(e)[:100]}")
    
    return reviews

# Danh s√°ch 20 th√†nh ph·ªë n·ªïi ti·∫øng nh·∫•t ·ªü Vi·ªát Nam v·ªõi t·ªça ƒë·ªô trung t√¢m
VIETNAM_CITIES = [
    {"name": "H√† N·ªôi", "lat": 21.0285, "lng": 105.8542},
    {"name": "Th√†nh ph·ªë H·ªì Ch√≠ Minh", "lat": 10.8231, "lng": 106.6297},
    {"name": "ƒê√† N·∫µng", "lat": 16.0544, "lng": 108.2022},
    {"name": "H·∫£i Ph√≤ng", "lat": 20.8449, "lng": 106.6881},
    {"name": "C·∫ßn Th∆°", "lat": 10.0452, "lng": 105.7469},
    {"name": "Nha Trang", "lat": 12.2388, "lng": 109.1967},
    {"name": "Hu·∫ø", "lat": 16.4637, "lng": 107.5909},
    {"name": "V≈©ng T√†u", "lat": 10.3460, "lng": 107.0843},
    # {"name": "Phan Thi·∫øt", "lat": 10.9376, "lng": 108.1018},
    # {"name": "Quy Nhon", "lat": 13.7765, "lng": 109.2237},
    # {"name": "H·∫° Long", "lat": 20.9101, "lng": 107.1839},
    # {"name": "Sapa", "lat": 22.3364, "lng": 103.8437},
    # {"name": "ƒê√† L·∫°t", "lat": 11.9404, "lng": 108.4583},
    # {"name": "H·ªôi An", "lat": 15.8801, "lng": 108.3380},
    # {"name": "Ph√∫ Qu·ªëc", "lat": 10.2899, "lng": 103.9840},
    # {"name": "M≈©i N√©", "lat": 10.9600, "lng": 108.2800},
    # {"name": "Tam ƒê·∫£o", "lat": 21.4500, "lng": 105.6500},
    # {"name": "C√°t B√†", "lat": 20.8000, "lng": 107.0167},
]

def main():
    """
    H√†m ch√≠nh ƒë·ªÉ t√¨m POI v√† scrape reviews cho 20 th√†nh ph·ªë n·ªïi ti·∫øng nh·∫•t ·ªü Vi·ªát Nam
    """
    print("\n" + "="*60)
    print("SCRAPER POI REVIEWS - Google Places API + Playwright")
    print("T·ª± ƒë·ªông ch·∫°y cho 20 th√†nh ph·ªë n·ªïi ti·∫øng nh·∫•t ·ªü Vi·ªát Nam")
    print("="*60)
    
    # H·ªèi s·ªë l∆∞·ª£ng POI t·ªëi ƒëa cho m·ªói th√†nh ph·ªë
    print("\nüìã Y√™u c·∫ßu: √çt nh·∫•t 70 POI m·ªói th√†nh ph·ªë, t·ªëi ƒëa 200 POI, m·ªói POI c√≥ > 100 reviews")
    max_results_input = input("S·ªë l∆∞·ª£ng POI t·ªëi ƒëa cho m·ªói th√†nh ph·ªë (m·∫∑c ƒë·ªãnh 200, nh·∫•n Enter ƒë·ªÉ d√πng m·∫∑c ƒë·ªãnh): ").strip()
    max_results_per_city = int(max_results_input) if max_results_input.isdigit() else 200
    min_results_per_city = 70  # Y√™u c·∫ßu t·ªëi thi·ªÉu 70 POI
    
    # H·ªèi c√≥ mu·ªën scrape reviews kh√¥ng
    scrape_reviews = input("\nB·∫°n c√≥ mu·ªën scrape reviews t·ª´ Google Maps kh√¥ng? (y/n, m·∫∑c ƒë·ªãnh: n): ").strip().lower()
    scrape_reviews = scrape_reviews == 'y'
    
    # T·∫°o th∆∞ m·ª•c reviews n·∫øu ch∆∞a c√≥
    os.makedirs('./reviews', exist_ok=True)
    
    # L∆∞u √Ω: M·ªói thread s·∫Ω t·∫°o browser ri√™ng v·ªõi Playwright
    # ƒêi·ªÅu n√†y gi√∫p tr√°nh conflict v√† cho ph√©p parallelization
    if scrape_reviews:
        print("\nüöÄ S·∫Ω s·ª≠ d·ª•ng Playwright v·ªõi parallelization (m·ªói thread c√≥ browser ri√™ng)")
        print("   ‚ö° Anti-detection: Random user agents, viewports, human-like behavior")
        print("   ‚ö° T·ªëc ƒë·ªô s·∫Ω nhanh h∆°n nh·ªù ch·∫°y song song nhi·ªÅu browser")
    
    # T·ªïng h·ª£p d·ªØ li·ªáu t·ª´ t·∫•t c·∫£ th√†nh ph·ªë
    all_reviews_data = []
    all_pois_summary = []
    
    # Ch·∫°y cho t·ª´ng th√†nh ph·ªë
    for city_idx, city in enumerate(VIETNAM_CITIES, 1):
        print("\n" + "‚ïê"*70)
        print(f"üèôÔ∏è  [{city_idx:2d}/{len(VIETNAM_CITIES)}] {city['name']}")
        print("‚ïê"*70)
        
        # T·∫°o nhi·ªÅu query kh√°c nhau ƒë·ªÉ t√¨m ƒë∆∞·ª£c nhi·ªÅu POI h∆°n
        queries = [
            f"ƒê·ªãa ƒëi·ªÉm du l·ªãch v√† th·∫Øng c·∫£nh ·ªü {city['name']}",
            f"B·∫£o t√†ng ·ªü {city['name']}",
            f"Ch√πa ·ªü {city['name']}",
            f"C√¥ng vi√™n ·ªü {city['name']}",
            f"Di t√≠ch l·ªãch s·ª≠ ·ªü {city['name']}",
            f"V∆∞·ªùng qu·ªëc gia ·ªü {city['name']}",
            f"Khu b·∫£o t·ªìn v√† du l·ªãch sinh th√°i ·ªü {city['name']}",
        ]
        
        location = f"{city['lat']},{city['lng']}"
        
        print(f"   üìç Location: ({city['lat']}, {city['lng']})")
        print(f"   üìã Y√™u c·∫ßu: {min_results_per_city}-{max_results_per_city} POI, m·ªói POI > 100 reviews")
        print(f"   üîç S·ª≠ d·ª•ng {len(queries)} query kh√°c nhau ƒë·ªÉ t√¨m POI...")
        
        try:
            # T√¨m ki·∫øm POI v·ªõi nhi·ªÅu query kh√°c nhau
            all_place_ids = set()
            pois = []
            
            for query_idx, query in enumerate(queries, 1):
                if len(pois) >= max_results_per_city:
                    print(f"\n   ‚úÖ ƒê√£ ƒë·∫°t {max_results_per_city} POI, d·ª´ng t√¨m ki·∫øm")
                    break
                
                remaining_needed = max_results_per_city - len(pois)
                if remaining_needed <= 0:
                    break
                
                print(f"\n   üîç Query {query_idx}/{len(queries)}: {query}")
                print(f"   üìä ƒê√£ c√≥: {len(pois)} POI, c·∫ßn th√™m: {remaining_needed} POI")
                
                # T√¨m ki·∫øm v·ªõi query n√†y, truy·ªÅn existing_place_ids ƒë·ªÉ tr√°nh tr√πng l·∫∑p
                query_pois = search_pois_by_text(
                    query, 
                    location, 
                    min_results=0,  # Kh√¥ng y√™u c·∫ßu t·ªëi thi·ªÉu cho t·ª´ng query
                    max_results=remaining_needed + 20,  # L·∫•y th√™m m·ªôt ch√∫t ƒë·ªÉ ƒë·∫£m b·∫£o
                    existing_place_ids=all_place_ids
                )
                
                # C·∫≠p nh·∫≠t place_ids
                for poi in query_pois:
                    all_place_ids.add(poi['place_id'])
                
                pois.extend(query_pois)
                
                print(f"   ‚úÖ Query n√†y t√¨m th·∫•y {len(query_pois)} POI m·ªõi, t·ªïng: {len(pois)} POI")
                
                # N·∫øu ƒë√£ ƒë·ªß, d·ª´ng l·∫°i
                if len(pois) >= min_results_per_city:
                    print(f"   ‚úÖ ƒê√£ ƒë·∫°t t·ªëi thi·ªÉu {min_results_per_city} POI")
                
                # ƒê·ª£i m·ªôt ch√∫t gi·ªØa c√°c query ƒë·ªÉ tr√°nh rate limit
                if query_idx < len(queries):
                    time.sleep(1)
            
            # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng POI
            pois = pois[:max_results_per_city]
            
            if not pois:
                print(f"\n   ‚ùå Kh√¥ng t√¨m th·∫•y POI n√†o ph√π h·ª£p")
                continue
            
            # Ki·ªÉm tra s·ªë l∆∞·ª£ng POI
            print(f"\n   {'‚îÄ'*66}")
            if len(pois) < min_results_per_city:
                print(f"   ‚ö†Ô∏è  C·∫£nh b√°o: {len(pois)}/{min_results_per_city} POI (thi·∫øu {min_results_per_city - len(pois)} POI)")
            else:
                print(f"   ‚úÖ T√¨m th·∫•y {len(pois)} POI (ƒë·∫°t y√™u c·∫ßu {min_results_per_city}-{max_results_per_city})")
            print(f"   {'‚îÄ'*66}")
            
            # Scrape reviews n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
            if scrape_reviews:
                num_threads = min(4, len(pois))
                print(f"\n   üìù Scraping reviews cho {len(pois)} POI")
                print(f"   ‚ö° Parallelization: {num_threads} threads")
                print(f"   {'‚îÄ'*66}")
                
                # Thread-safe lock cho vi·ªác append v√†o all_reviews_data
                data_lock = Lock()
                
                def scrape_poi_reviews(poi_data):
                    """Wrapper function ƒë·ªÉ scrape reviews cho m·ªôt POI v·ªõi Playwright"""
                    idx, poi = poi_data
                    browser = None
                    context = None
                    page = None
                    
                    try:
                        # Random delay tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu ƒë·ªÉ tr√°nh rate limiting
                        human_delay(0.5, 2.0)
                        
                        # T·∫°o browser ri√™ng cho m·ªói thread v·ªõi Playwright
                        with sync_playwright() as playwright:
                            browser, context, page = setup_playwright_browser(playwright)
                            
                            if not browser or not page:
                                print(f"      [{idx:3d}/{len(pois)}] ‚ö†Ô∏è  Kh√¥ng th·ªÉ t·∫°o browser: {poi['name'][:40]}")
                                return []
                            
                            print(f"      [{idx:3d}/{len(pois)}] üîÑ {poi['name'][:45]:<45} | {poi['user_rating_total']:>6} reviews")
                            
                            reviews = scrape_reviews_from_google_maps(poi['place_id'], page, min_reviews=90, max_reviews=120)
                            
                            # Tr·∫£ v·ªÅ c·∫£ s·ªë reviews ƒë·ªÉ x·ª≠ l√Ω sau
                            review_count = len(reviews) if reviews else 0
                            
                            # Ch·ªâ l∆∞u POI c√≥ s·ªë reviews >= 90 (t·ªëi thi·ªÉu)
                            if review_count >= 90:
                                print(f"      [{idx:3d}/{len(pois)}] ‚úÖ {poi['name'][:45]:<45} | {review_count:>3d} reviews (ƒë·ªß ƒëi·ªÅu ki·ªán >= 90)")
                                return [(poi['place_id'], review_count, review) for review in reviews]
                            elif review_count > 0:
                                print(f"      [{idx:3d}/{len(pois)}] ‚è≠Ô∏è  {poi['name'][:45]:<45} | {review_count:>3d} reviews (b·ªè qua, < 90)")
                                return [(poi['place_id'], review_count, None)]  # Tr·∫£ v·ªÅ v·ªõi review_count nh∆∞ng kh√¥ng c√≥ reviews
                            else:
                                print(f"      [{idx:3d}/{len(pois)}] ‚ö†Ô∏è  {poi['name'][:45]:<45} | 0 reviews")
                                return [(poi['place_id'], 0, None)]
                    except Exception as e:
                        error_msg = str(e)[:50]
                        if "Timeout" in error_msg:
                            print(f"      [{idx:3d}/{len(pois)}] ‚è±Ô∏è  {poi['name'][:45]:<45} | Timeout")
                        else:
                            print(f"      [{idx:3d}/{len(pois)}] ‚ùå {poi['name'][:45]:<45} | L·ªói: {error_msg}")
                        return []
                    finally:
                        # Cleanup v·ªõi delay ƒë·ªÉ tr√°nh ƒë√≥ng qu√° nhanh
                        try:
                            human_delay(0.5, 1.0)
                            if page:
                                page.close()
                            if context:
                                context.close()
                            if browser:
                                browser.close()
                        except:
                            pass
                
                # S·ª≠ d·ª•ng ThreadPoolExecutor ƒë·ªÉ parallelize
                max_workers = min(4, len(pois))  # T·ªëi ƒëa 4 threads ƒë·ªÉ tr√°nh qu√° t·∫£i
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    # Submit t·∫•t c·∫£ tasks
                    future_to_poi = {
                        executor.submit(scrape_poi_reviews, (idx, poi)): poi 
                        for idx, poi in enumerate(pois, 1)
                    }
                    
                    # X·ª≠ l√Ω k·∫øt qu·∫£ khi ho√†n th√†nh
                    poi_review_counts = {}  # ƒê·∫øm s·ªë reviews cho m·ªói POI
                    for future in as_completed(future_to_poi):
                        poi = future_to_poi[future]
                        try:
                            results = future.result()
                            if results:
                                # L·∫•y place_id v√† review_count t·ª´ k·∫øt qu·∫£
                                place_id = results[0][0] if results else None
                                review_count = results[0][1] if results and len(results[0]) > 1 else 0
                                
                                if place_id:
                                    poi_review_counts[place_id] = review_count
                                
                                # Thread-safe append (ch·ªâ append reviews n·∫øu >= 90)
                                if review_count >= 90:
                                    with data_lock:
                                        for result in results:
                                            if len(result) > 2 and result[2] is not None:  # C√≥ review text
                                                all_reviews_data.append({
                                                    'placeID': result[0],
                                                    'reviews': result[2]
                                                })
                        except Exception as e:
                            print(f"      ‚ùå L·ªói x·ª≠ l√Ω k·∫øt qu·∫£: {str(e)[:50]}")
                    
                    # C·∫≠p nh·∫≠t all_pois_summary: ch·ªâ gi·ªØ POI c√≥ >= 90 reviews
                    filtered_pois_summary = []
                    for poi in pois:
                        place_id = poi['place_id']
                        review_count = poi_review_counts.get(place_id, 0)
                        if review_count >= 90:
                            filtered_pois_summary.append({
                                'city': city['name'],
                                'place_id': place_id,
                                'name': poi['name'],
                                'user_rating_total': poi['user_rating_total']
                            })
                    
                    # C·∫≠p nh·∫≠t all_pois_summary v·ªõi filtered list (ch·ªâ POI c√≥ >= 90 reviews)
                    with data_lock:
                        all_pois_summary.extend(filtered_pois_summary)
                    
                    # Th·ªëng k√™
                    total_pois = len(pois)
                    qualified_pois = len(filtered_pois_summary)
                    print(f"\n   ‚úÖ Ho√†n t·∫•t: {total_pois} POI ƒë√£ x·ª≠ l√Ω, {qualified_pois} POI c√≥ >= 90 reviews (ƒë·ªß ƒëi·ªÅu ki·ªán)")
            else:
                # N·∫øu kh√¥ng scrape reviews, kh√¥ng l∆∞u POI n√†o v√†o summary
                # (v√¨ kh√¥ng bi·∫øt s·ªë reviews th·ª±c t·∫ø)
                print(f"\n   ‚ö†Ô∏è  Kh√¥ng scrape reviews, kh√¥ng l∆∞u POI v√†o summary")
            
        except Exception as e:
            print(f"‚ùå L·ªói khi x·ª≠ l√Ω {city['name']}: {e}")
            import traceback
            traceback.print_exc()
            continue  # Ti·∫øp t·ª•c v·ªõi th√†nh ph·ªë ti·∫øp theo
        
        # Ngh·ªâ gi·ªØa c√°c th√†nh ph·ªë
        if city_idx < len(VIETNAM_CITIES):
            print(f"\n   ‚è≥ ƒê·ª£i 3 gi√¢y tr∆∞·ªõc khi chuy·ªÉn sang th√†nh ph·ªë ti·∫øp theo...\n")
            time.sleep(3)
    
    # Kh√¥ng c·∫ßn ƒë√≥ng driver ·ªü ƒë√¢y v√¨ m·ªói thread ƒë√£ t·ª± ƒë√≥ng driver c·ªßa n√≥
    
    # L∆∞u summary POI
    summary_file = './reviews/pois_summary.csv'
    print(f"\n{'‚ïê'*70}")
    print(f"üíæ L∆ØU D·ªÆ LI·ªÜU")
    print(f"{'‚ïê'*70}")
    print(f"   üìÑ ƒêang l∆∞u summary POI...")
    try:
        with open(summary_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=['city', 'place_id', 'name', 'user_rating_total'])
            writer.writeheader()
            writer.writerows(all_pois_summary)
        print(f"   ‚úÖ ƒê√£ l∆∞u {len(all_pois_summary)} POI ‚Üí {summary_file}")
    except Exception as e:
        print(f"   ‚ùå L·ªói khi l∆∞u summary: {e}")
    
    # L∆∞u reviews v√†o CSV (n·∫øu c√≥)
    if all_reviews_data:
        output_file = './reviews/all_reviews.csv'
        print(f"   üìÑ ƒêang l∆∞u {len(all_reviews_data):,} reviews...")
        
        try:
            # Ki·ªÉm tra file ƒë√£ t·ªìn t·∫°i ch∆∞a ƒë·ªÉ append ho·∫∑c t·∫°o m·ªõi
            file_exists = os.path.exists(output_file)
            with open(output_file, 'a' if file_exists else 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=['placeID', 'reviews'])
                if not file_exists:
                    writer.writeheader()
                writer.writerows(all_reviews_data)
            
            print(f"   ‚úÖ ƒê√£ l∆∞u {len(all_reviews_data):,} reviews ‚Üí {output_file}")
            
            # Th·ªëng k√™ theo th√†nh ph·ªë
            city_stats = {}
            for poi in all_pois_summary:
                city = poi['city']
                if city not in city_stats:
                    city_stats[city] = {'pois': 0, 'reviews': 0}
                city_stats[city]['pois'] += 1
            
            # ƒê·∫øm reviews theo placeID v√† map v·ªÅ city
            poi_to_city = {poi['place_id']: poi['city'] for poi in all_pois_summary}
            for row in all_reviews_data:
                place_id = row['placeID']
                if place_id in poi_to_city:
                    city = poi_to_city[place_id]
                    city_stats[city]['reviews'] += 1
            
            print(f"\n   üìä Th·ªëng k√™ theo th√†nh ph·ªë:")
            print(f"   {'‚îÄ'*66}")
            for city, stats in sorted(city_stats.items()):
                print(f"   {city:30s} | {stats['pois']:3d} POI | {stats['reviews']:6,} reviews")
            
        except Exception as e:
            print(f"   ‚ùå L·ªói khi l∆∞u file CSV: {e}")
    else:
        print(f"   ‚ö†Ô∏è  Kh√¥ng c√≥ reviews n√†o ƒë∆∞·ª£c scrape")
    
    # T·ªïng k·∫øt
    print(f"\n{'‚ïê'*70}")
    print(f"‚úÖ HO√ÄN T·∫§T!")
    print(f"{'‚ïê'*70}")
    print(f"   üèôÔ∏è  Th√†nh ph·ªë ƒë√£ x·ª≠ l√Ω: {len(VIETNAM_CITIES)}")
    print(f"   üìç T·ªïng s·ªë POI: {len(all_pois_summary):,}")
    if all_reviews_data:
        print(f"   üìù T·ªïng s·ªë reviews: {len(all_reviews_data):,}")
    print(f"   üíæ File summary: {summary_file}")
    if all_reviews_data:
        print(f"   üíæ File reviews: ./reviews/all_reviews.csv")
    print(f"{'‚ïê'*70}\n")

if __name__ == "__main__":
    main()

