"""
Script ƒë·ªÉ t√¨m ki·∫øm POI b·∫±ng Google Text Search API v√† scrape reviews b·∫±ng Playwright
- T√¨m POI b·∫±ng Google Places API (Text Search)
- L·ªçc POI c√≥ s·ªë l∆∞·ª£ng reviews > 100
- Scrape reviews t·ª´ Google Maps b·∫±ng Playwright (v·ªõi anti-detection)
- Xu·∫•t ra file reviews.csv v·ªõi c√°c c·ªôt: placeID, reviews
"""

import os
import time
import csv
import json
import requests
import random
import urllib3
from dotenv import load_dotenv
from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeoutError
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

# Disable SSL warnings v√† verification (ƒë·ªÉ x·ª≠ l√Ω l·ªói certificate tr√™n Windows)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# T·∫°o session v·ªõi SSL verification disabled
def create_requests_session():
    """
    T·∫°o requests session v·ªõi SSL verification disabled ƒë·ªÉ x·ª≠ l√Ω l·ªói certificate tr√™n Windows
    """
    session = requests.Session()
    session.verify = False  # Disable SSL verification
    return session

# Load bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()

# Google Places API Key
GOOGLE_PLACES_API_KEY = os.getenv('GOOGLE_PLACES_API_KEY', '')

if not GOOGLE_PLACES_API_KEY:
    print("‚ö†Ô∏è  C·∫¢NH B√ÅO: GOOGLE_PLACES_API_KEY ch∆∞a ƒë∆∞·ª£c set trong bi·∫øn m√¥i tr∆∞·ªùng!")
    print("   H√£y set: export GOOGLE_PLACES_API_KEY='your_key'")
    exit(1)
else:
    print(f"‚úÖ GOOGLE_PLACES_API_KEY ƒë√£ ƒë∆∞·ª£c set (ƒë·ªô d√†i: {len(GOOGLE_PLACES_API_KEY)} k√Ω t·ª±)")

def search_pois_by_text(query: str, location: str = None, min_results: int = 65, max_results: int = 200):
    """
    T√¨m ki·∫øm POI b·∫±ng Google Places API (Text Search) v·ªõi pagination
    
    Args:
        query: T·ª´ kh√≥a t√¨m ki·∫øm (v√≠ d·ª•: "restaurants in Ho Chi Minh City")
        location: V·ªã tr√≠ t√¨m ki·∫øm (optional, format: "lat,lng")
        min_results: S·ªë l∆∞·ª£ng POI t·ªëi thi·ªÉu c·∫ßn l·∫•y (m·∫∑c ƒë·ªãnh 65)
        max_results: S·ªë l∆∞·ª£ng k·∫øt qu·∫£ t·ªëi ƒëa mu·ªën l·∫•y (m·∫∑c ƒë·ªãnh 200)
    
    Returns:
        List c√°c POI v·ªõi place_id, name, user_rating_total
    """
    url = "https://places.googleapis.com/v1/places:searchText"
    
    headers = {
        'Content-Type': 'application/json',
        'X-Goog-Api-Key': GOOGLE_PLACES_API_KEY,
        'X-Goog-FieldMask': 'places.id,places.displayName,places.userRatingCount,nextPageToken'
    }
    
    # T·∫°o request body
    body = {
        "textQuery": query,
        "maxResultCount": 20  # T·ªëi ƒëa 20 k·∫øt qu·∫£ m·ªói request
    }
    
    if location:
        # Parse location n·∫øu c√≥
        try:
            lat, lng = map(float, location.split(','))
            body["locationBias"] = {
                "circle": {
                    "center": {
                        "latitude": lat,
                        "longitude": lng
                    },
                    "radius": 5000.0  # 5km radius
                }
            }
        except:
            pass
    
    # T·∫°o session v·ªõi SSL verification disabled
    session = create_requests_session()
    
    all_pois = []
    next_page_token = None
    page_count = 0
    
    try:
        while True:
            page_count += 1
            print(f"\n{'‚îÄ'*60}")
            print(f"üìÑ Trang {page_count} | ƒê√£ l·∫•y: {len(all_pois)}/{max_results} POI")
            print(f"{'‚îÄ'*60}")
            
            # N·∫øu c√≥ nextPageToken t·ª´ l·∫ßn tr∆∞·ªõc, th√™m v√†o body
            if next_page_token:
                body["pageToken"] = next_page_token
            
            # G·ªçi API v·ªõi session ƒë√£ disable SSL verification
            response = session.post(url, headers=headers, json=body, timeout=10)
            
            if response.status_code != 200:
                print(f"‚ùå L·ªói API: HTTP {response.status_code}")
                print(f"   Chi ti·∫øt: {response.text[:200]}")
                break
            
            data = response.json()
            places = data.get('places', [])
            next_page_token = data.get('nextPageToken')
            
            print(f"   üì• Nh·∫≠n ƒë∆∞·ª£c {len(places)} POI t·ª´ API")
            
            # X·ª≠ l√Ω t·ª´ng place
            valid_count = 0
            skipped_count = 0
            for place in places:
                place_id = place.get('id', '')
                name = place.get('displayName', {}).get('text', '') if isinstance(place.get('displayName'), dict) else place.get('displayName', '')
                user_rating_count = place.get('userRatingCount', 0)
                
                # Ch·ªâ l·∫•y POI c√≥ s·ªë l∆∞·ª£ng reviews > 100
                if user_rating_count and user_rating_count > 100:
                    all_pois.append({
                        'place_id': place_id,
                        'name': name,
                        'user_rating_total': user_rating_count
                    })
                    valid_count += 1
                    print(f"   ‚úÖ [{len(all_pois):3d}] {name[:50]:<50} | {user_rating_count:>6} reviews")
                else:
                    skipped_count += 1
                    if skipped_count <= 3:  # Ch·ªâ hi·ªÉn th·ªã 3 POI ƒë·∫ßu ti√™n b·ªã b·ªè qua
                        print(f"   ‚è≠Ô∏è  [{skipped_count:3d}] {name[:50]:<50} | {user_rating_count:>6} reviews (b·ªè qua)")
            
            if skipped_count > 3:
                print(f"   ‚è≠Ô∏è  ... v√† {skipped_count - 3} POI kh√°c b·ªã b·ªè qua (< 100 reviews)")
            
            print(f"   üìä Trang n√†y: {valid_count} h·ª£p l·ªá, {skipped_count} b·ªè qua")
            
            # Ki·ªÉm tra ƒëi·ªÅu ki·ªán d·ª´ng
            if not next_page_token:
                print(f"\n   ‚èπÔ∏è  Kh√¥ng c√≤n trang ti·∫øp theo")
                if len(all_pois) < min_results:
                    print(f"   ‚ö†Ô∏è  C·∫£nh b√°o: Ch·ªâ l·∫•y ƒë∆∞·ª£c {len(all_pois)}/{min_results} POI (thi·∫øu {min_results - len(all_pois)} POI)")
                break
            
            if len(all_pois) >= max_results:
                print(f"\n   ‚úÖ ƒê√£ ƒë·∫°t gi·ªõi h·∫°n {max_results} POI")
                break
            
            # N·∫øu ƒë√£ ƒë·ªß min_results nh∆∞ng ch∆∞a ƒë·∫°t max_results, v·∫´n ti·∫øp t·ª•c ƒë·ªÉ l·∫•y th√™m
            if len(all_pois) >= min_results and len(all_pois) < max_results:
                remaining = max_results - len(all_pois)
                print(f"   üìà ƒê√£ ƒë·ªß {min_results} POI, ti·∫øp t·ª•c l·∫•y th√™m {remaining} POI...")
            
            # ƒê·ª£i m·ªôt ch√∫t tr∆∞·ªõc khi g·ªçi request ti·∫øp theo (tr√°nh rate limit)
            print(f"   ‚è≥ ƒê·ª£i 2 gi√¢y tr∆∞·ªõc khi l·∫•y trang ti·∫øp theo...")
            time.sleep(2)
            
            # X√≥a pageToken kh·ªèi body ƒë·ªÉ tr√°nh l·ªói n·∫øu kh√¥ng c√≥ nextPageToken
            if 'pageToken' in body:
                del body['pageToken']
        
        print(f"\n{'‚ïê'*60}")
        print(f"‚úÖ Ho√†n t·∫•t: {len(all_pois)} POI h·ª£p l·ªá t·ª´ {page_count} trang")
        print(f"{'‚ïê'*60}\n")
        return all_pois[:max_results]  # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng k·∫øt qu·∫£
        
    except Exception as e:
        print(f"‚ùå L·ªói khi g·ªçi API: {e}")
        import traceback
        traceback.print_exc()
        return all_pois  # Tr·∫£ v·ªÅ nh·ªØng g√¨ ƒë√£ l·∫•y ƒë∆∞·ª£c

# User agents pool ƒë·ªÉ randomize
USER_AGENTS = [
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
]

# Viewport sizes ƒë·ªÉ randomize
VIEWPORT_SIZES = [
    {"width": 1920, "height": 1080},
    {"width": 1366, "height": 768},
    {"width": 1536, "height": 864},
    {"width": 1440, "height": 900},
    {"width": 1280, "height": 720},
]

def human_delay(min_seconds=0.5, max_seconds=2.0):
    """Random delay ƒë·ªÉ m√¥ ph·ªèng h√†nh vi con ng∆∞·ªùi"""
    delay = random.uniform(min_seconds, max_seconds)
    time.sleep(delay)

def human_scroll(page, container=None, steps=3):
    """Scroll gi·ªëng con ng∆∞·ªùi v·ªõi random pauses"""
    if container:
        # Scroll trong container
        for i in range(steps):
            scroll_amount = random.randint(200, 500)
            try:
                page.evaluate(f"""
                    (container) => {{
                        container.scrollTop += {scroll_amount};
                    }}
                """, container.element_handle())
            except:
                # Fallback: scroll page
                page.mouse.wheel(0, scroll_amount)
            human_delay(0.3, 0.8)
    else:
        # Scroll trang
        for i in range(steps):
            scroll_amount = random.randint(300, 600)
            page.mouse.wheel(0, scroll_amount)
            human_delay(0.4, 1.0)

def setup_playwright_browser(playwright):
    """
    Thi·∫øt l·∫≠p Playwright Browser v·ªõi anti-detection
    """
    try:
        # Random user agent v√† viewport
        user_agent = random.choice(USER_AGENTS)
        viewport = random.choice(VIEWPORT_SIZES)
        
        # Launch browser v·ªõi stealth mode v√† th√™m args ƒë·ªÉ tr√°nh detection
        browser = playwright.chromium.launch(
            headless=True,  # C√≥ th·ªÉ ƒë·ªïi th√†nh False ƒë·ªÉ debug
            args=[
                '--disable-blink-features=AutomationControlled',
                '--disable-dev-shm-usage',
                '--no-sandbox',
                '--disable-setuid-sandbox',
                '--disable-web-security',
                '--disable-features=IsolateOrigins,site-per-process',
                '--disable-infobars',
                '--disable-notifications',
                '--disable-popup-blocking',
                '--start-maximized',
                '--disable-extensions',
                '--disable-plugins-discovery',
                '--disable-default-apps',
            ]
        )
        
        # T·∫°o context v·ªõi anti-detection settings
        context = browser.new_context(
            viewport=viewport,
            user_agent=user_agent,
            locale='en-US',
            timezone_id='America/New_York',
            permissions=['geolocation'],
            geolocation={'latitude': 10.8231, 'longitude': 106.6297},  # HCM coordinates
            color_scheme='light',
            # Th√™m extra HTTP headers
            extra_http_headers={
                'Accept-Language': 'en-US,en;q=0.9',
                'Accept-Encoding': 'gzip, deflate, br',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
            }
        )
        
        # Inject stealth scripts ƒë·ªÉ ·∫©n automation (n√¢ng cao)
        context.add_init_script("""
            // Override navigator.webdriver
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
            
            // Override chrome object
            window.chrome = {
                runtime: {},
                loadTimes: function() {},
                csi: function() {},
                app: {}
            };
            
            // Override permissions
            const originalQuery = window.navigator.permissions.query;
            window.navigator.permissions.query = (parameters) => (
                parameters.name === 'notifications' ?
                    Promise.resolve({ state: Notification.permission }) :
                    originalQuery(parameters)
            );
            
            // Override plugins
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5]
            });
            
            // Override languages
            Object.defineProperty(navigator, 'languages', {
                get: () => ['en-US', 'en']
            });
            
            // Override platform
            Object.defineProperty(navigator, 'platform', {
                get: () => 'MacIntel'
            });
            
            // Override hardwareConcurrency
            Object.defineProperty(navigator, 'hardwareConcurrency', {
                get: () => 8
            });
            
            // Override deviceMemory
            Object.defineProperty(navigator, 'deviceMemory', {
                get: () => 8
            });
            
            // Override getBattery
            if (navigator.getBattery) {
                navigator.getBattery = () => Promise.resolve({
                    charging: true,
                    chargingTime: 0,
                    dischargingTime: Infinity,
                    level: 1
                });
            }
            
            // Override connection
            Object.defineProperty(navigator, 'connection', {
                get: () => ({
                    effectiveType: '4g',
                    rtt: 50,
                    downlink: 10,
                    saveData: false
                })
            });
        """)
        
        page = context.new_page()
        
        return browser, context, page
        
    except Exception as e:
        print(f"‚ùå L·ªói khi kh·ªüi t·∫°o Playwright Browser: {e}")
        print("   G·ª£i √Ω: Ch·∫°y 'playwright install chromium' ƒë·ªÉ c√†i ƒë·∫∑t browser")
        return None, None, None

def scrape_reviews_from_google_maps(place_id: str, page, max_reviews: int = 150):
    """
    Scrape reviews t·ª´ Google Maps b·∫±ng Playwright v·ªõi anti-detection
    
    Args:
        place_id: Place ID c·ªßa POI
        page: Playwright Page instance
        max_reviews: S·ªë l∆∞·ª£ng reviews t·ªëi ƒëa c·∫ßn l·∫•y
    
    Returns:
        List c√°c review text
    """
    # URL Google Maps cho place_id
    url = f"https://www.google.com/maps/place/?q=place_id:{place_id}"
    
    reviews = []
    
    try:
        # Navigate v·ªõi human-like behavior v√† retry logic
        max_retries = 3
        retry_count = 0
        navigation_success = False
        
        while retry_count < max_retries and not navigation_success:
            try:
                # TƒÉng timeout v√† d√πng 'domcontentloaded' thay v√¨ 'networkidle' ƒë·ªÉ nhanh h∆°n
                page.goto(url, wait_until='domcontentloaded', timeout=60000)
                navigation_success = True
                human_delay(3.0, 5.0)  # ƒê·ª£i trang load ho√†n to√†n
            except PlaywrightTimeoutError:
                retry_count += 1
                if retry_count < max_retries:
                    print(f"      ‚ö†Ô∏è  Timeout l·∫ßn {retry_count}, retry...")
                    human_delay(2.0, 4.0)  # ƒê·ª£i tr∆∞·ªõc khi retry
                else:
                    print(f"      ‚ùå Timeout sau {max_retries} l·∫ßn th·ª≠")
                    return []
        
        if not navigation_success:
            return []
        
        # Random mouse movement ƒë·ªÉ m√¥ ph·ªèng con ng∆∞·ªùi
        page.mouse.move(random.randint(100, 500), random.randint(100, 500))
        human_delay(0.5, 1.0)
        
        # ƒê·ª£i th√™m ƒë·ªÉ ƒë·∫£m b·∫£o trang ƒë√£ load ƒë·∫ßy ƒë·ªß
        try:
            page.wait_for_load_state('networkidle', timeout=10000)
        except:
            pass  # B·ªè qua n·∫øu timeout, trang c√≥ th·ªÉ ƒë√£ load ƒë·ªß
        
        try:
            # B∆∞·ªõc 1: T√¨m v√† click v√†o button "Reviews" ho·∫∑c tab "Reviews"
            review_button_selectors = [
                "button[data-value='Reviews']",
                "button:has-text('Reviews')",
                "button[aria-label*='Review']",
                "//button[contains(text(), 'Reviews')]",
                "//span[contains(text(), 'Reviews')]/ancestor::button",
            ]
            
            review_button_clicked = False
            for selector in review_button_selectors:
                try:
                    if selector.startswith("//"):
                        button = page.locator(selector).first
                    else:
                        button = page.locator(selector).first
                    
                    if button.is_visible(timeout=2000):
                        # Human-like click v·ªõi mouse movement
                        box = button.bounding_box()
                        if box:
                            # Move mouse ƒë·∫øn button tr∆∞·ªõc khi click
                            page.mouse.move(box['x'] + box['width']/2, box['y'] + box['height']/2)
                            human_delay(0.2, 0.5)
                            button.click(timeout=5000)
                            review_button_clicked = True
                            human_delay(2.0, 3.5)  # ƒê·ª£i ph·∫ßn reviews load
                            break
                except:
                    continue
            
            # B∆∞·ªõc 2: Scroll xu·ªëng ƒë·ªÉ t√¨m ph·∫ßn reviews n·∫øu ch∆∞a click ƒë∆∞·ª£c
            if not review_button_clicked:
                human_scroll(page, steps=3)
                human_delay(1.0, 2.0)
            
            # B∆∞·ªõc 3: T√¨m ph·∫ßn t·ª≠ feed ch·ª©a reviews (role="feed" ho·∫∑c aria-label li√™n quan ƒë·∫øn reviews)
            review_feed = None
            
            # Th·ª≠ t√¨m theo role="feed" tr∆∞·ªõc (c√°ch t·ªët nh·∫•t)
            try:
                feed_elements = page.locator('[role="feed"]').all()
                for feed in feed_elements:
                    if feed.is_visible(timeout=1000):
                        # Ki·ªÉm tra xem c√≥ li√™n quan ƒë·∫øn reviews kh√¥ng
                        aria_label = feed.get_attribute('aria-label') or ''
                        if 'review' in aria_label.lower() or 'ƒë√°nh gi√°' in aria_label.lower() or aria_label == '':
                            review_feed = feed
                            break
            except:
                pass
            
            # N·∫øu kh√¥ng t√¨m th·∫•y, th·ª≠ t√¨m theo aria-label
            if not review_feed:
                try:
                    feed_selectors = [
                        '[aria-label*="Review"]',
                        '[aria-label*="review"]',
                        '[aria-label*="ƒê√°nh gi√°"]',
                        '[aria-label*="ƒë√°nh gi√°"]',
                        'div[role="feed"]',
                    ]
                    for selector in feed_selectors:
                        try:
                            feeds = page.locator(selector).all()
                            for feed in feeds:
                                if feed.is_visible(timeout=1000):
                                    review_feed = feed
                                    break
                            if review_feed:
                                break
                        except:
                            continue
                except:
                    pass
            
            # Fallback: T√¨m container reviews truy·ªÅn th·ªëng
            if not review_feed:
                review_container_selectors = [
                    "div.m6QErb[aria-label*='Review']",
                    "div[data-section-id='reviews']",
                    "div.m6QErb",
                ]
                
                for selector in review_container_selectors:
                    try:
                        containers = page.locator(selector).all()
                        for container in containers:
                            if container.is_visible(timeout=1000):
                                review_feed = container
                                break
                        if review_feed:
                            break
                    except:
                        continue
            
            # B∆∞·ªõc 4: Scroll trong ph·∫ßn reviews feed ƒë·ªÉ load th√™m reviews
            scroll_attempts = 0
            max_scroll_attempts = 100  # TƒÉng l√™n 100 l·∫ßn scroll
            last_review_count = 0
            no_change_count = 0
            min_scrolls_before_stop = 30  # Ph·∫£i scroll √≠t nh·∫•t 30 l·∫ßn tr∆∞·ªõc khi c√≥ th·ªÉ d·ª´ng
            
            while scroll_attempts < max_scroll_attempts and len(reviews) < max_reviews:
                scroll_attempts += 1
                
                # Human-like scroll v·ªõi random delay
                if review_feed:
                    # Scroll trong feed element b·∫±ng JavaScript
                    try:
                        scroll_amount = random.randint(300, 800)  # TƒÉng scroll amount
                        # D√πng page.evaluate() ƒë·ªÉ scroll ph·∫ßn t·ª≠ feed
                        page.evaluate("""
                            (feedElement, scrollAmount) => {
                                if (feedElement) {
                                    // Scroll xu·ªëng
                                    feedElement.scrollTop += scrollAmount;
                                    
                                    // Ho·∫∑c scroll ƒë·∫øn cu·ªëi n·∫øu g·∫ßn cu·ªëi
                                    const maxScroll = feedElement.scrollHeight - feedElement.clientHeight;
                                    if (feedElement.scrollTop + scrollAmount >= maxScroll * 0.9) {
                                        feedElement.scrollTop = feedElement.scrollHeight;
                                    }
                                }
                            }
                        """, review_feed.element_handle(), scroll_amount)
                    except Exception as e:
                        # Fallback: scroll page
                        try:
                            page.mouse.wheel(0, random.randint(400, 700))
                        except:
                            pass
                else:
                    # Scroll trang n·∫øu kh√¥ng t√¨m th·∫•y feed
                    human_scroll(page, steps=random.randint(1, 3))
                
                # Random delay ƒë·ªÉ m√¥ ph·ªèng h√†nh vi con ng∆∞·ªùi (1.5-3.5 gi√¢y)
                human_delay(1.5, 3.5)
                
                # T√¨m v√† l·∫•y reviews sau m·ªói l·∫ßn scroll
                review_texts = set()
                
                # C√°c selector cho Google Maps reviews
                selectors = [
                    "span.wiI7pd",
                    "div.MyEned span.wiI7pd",
                    "div.jftiEf span.wiI7pd",
                    "div[data-review-id] span.wiI7pd",
                    "span[data-review-id] span.wiI7pd",
                    "div.MyEned",
                ]
                
                for selector in selectors:
                    try:
                        elements = page.locator(selector).all()
                        for elem in elements:
                            try:
                                text = elem.inner_text(timeout=500).strip() if elem.is_visible(timeout=500) else ""
                                # L·ªçc text h·ª£p l·ªá
                                if (text and 
                                    len(text) > 15 and 
                                    len(text) < 5000 and
                                    not text.isdigit() and
                                    not text.startswith('‚òÖ') and
                                    ':' not in text[:15] and
                                    'See more' not in text and
                                    'Show more' not in text and
                                    'Helpful' not in text and
                                    'Translate' not in text):
                                    review_texts.add(text)
                            except:
                                continue
                    except:
                        continue
                
                # C·∫≠p nh·∫≠t reviews
                current_count = len(review_texts)
                if current_count > last_review_count:
                    last_review_count = current_count
                    no_change_count = 0  # Reset counter khi c√≥ reviews m·ªõi
                else:
                    no_change_count += 1
                    # Ch·ªâ d·ª´ng n·∫øu ƒë√£ scroll √≠t nh·∫•t min_scrolls_before_stop l·∫ßn V√Ä kh√¥ng c√≥ thay ƒë·ªïi trong 10 l·∫ßn li√™n ti·∫øp
                    if scroll_attempts >= min_scrolls_before_stop and no_change_count >= 10:
                        break
                
                # C·∫≠p nh·∫≠t danh s√°ch reviews
                reviews = list(review_texts)
            
            # B∆∞·ªõc 5: Th·ª≠ click "See more" ho·∫∑c "Show more reviews" n·∫øu c√≥
            try:
                see_more_selectors = [
                    "button:has-text('See more')",
                    "button:has-text('Show more')",
                    "//button[contains(text(), 'See more')]",
                    "//button[contains(text(), 'Show more')]",
                    "//button[@aria-label and contains(@aria-label, 'more')]",
                ]
                
                for selector in see_more_selectors:
                    try:
                        if selector.startswith("//"):
                            button = page.locator(selector).first
                        else:
                            button = page.locator(selector).first
                        
                        if button.is_visible(timeout=2000):
                            # Human-like click
                            box = button.bounding_box()
                            if box:
                                page.mouse.move(box['x'] + box['width']/2, box['y'] + box['height']/2)
                                human_delay(0.2, 0.5)
                                button.click(timeout=5000)
                                human_delay(2.0, 3.0)
                                
                                # Scroll th√™m sau khi click
                                if review_feed:
                                    for i in range(10):  # TƒÉng s·ªë l·∫ßn scroll sau khi click
                                        try:
                                            scroll_amount = random.randint(300, 800)
                                            page.evaluate("""
                                                (feedElement, scrollAmount) => {
                                                    if (feedElement) {
                                                        feedElement.scrollTop += scrollAmount;
                                                    }
                                                }
                                            """, review_feed.element_handle(), scroll_amount)
                                            human_delay(0.5, 1.2)
                                        except:
                                            page.mouse.wheel(0, random.randint(400, 700))
                                            human_delay(0.6, 1.3)
                                else:
                                    human_scroll(page, steps=10)
                                
                                # L·∫•y l·∫°i reviews sau khi click
                                review_texts = set()
                                for selector in selectors:
                                    try:
                                        elements = page.locator(selector).all()
                                        for elem in elements:
                                            try:
                                                text = elem.inner_text(timeout=500).strip() if elem.is_visible(timeout=500) else ""
                                                if (text and 
                                                    len(text) > 15 and 
                                                    len(text) < 5000 and
                                                    not text.isdigit() and
                                                    not text.startswith('‚òÖ') and
                                                    ':' not in text[:15] and
                                                    'See more' not in text and
                                                    'Show more' not in text and
                                                    'Helpful' not in text and
                                                    'Translate' not in text):
                                                    review_texts.add(text)
                                            except:
                                                continue
                                    except:
                                        continue
                                
                                reviews = list(review_texts)
                                break
                    except:
                        continue
            except:
                pass
            
            # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng reviews
            reviews = reviews[:max_reviews]
            
        except PlaywrightTimeoutError:
            print(f"      ‚ö†Ô∏è  Timeout khi ƒë·ª£i reviews load")
        except Exception as e:
            print(f"      ‚ö†Ô∏è  L·ªói: {str(e)[:100]}")
        
    except Exception as e:
        print(f"      ‚ùå L·ªói: {str(e)[:100]}")
    
    return reviews

# Danh s√°ch 20 th√†nh ph·ªë n·ªïi ti·∫øng nh·∫•t ·ªü Vi·ªát Nam v·ªõi t·ªça ƒë·ªô trung t√¢m
VIETNAM_CITIES = [
    {"name": "H√† N·ªôi", "lat": 21.0285, "lng": 105.8542},
    {"name": "Th√†nh ph·ªë H·ªì Ch√≠ Minh", "lat": 10.8231, "lng": 106.6297},
    {"name": "ƒê√† N·∫µng", "lat": 16.0544, "lng": 108.2022},
    {"name": "H·∫£i Ph√≤ng", "lat": 20.8449, "lng": 106.6881},
    {"name": "C·∫ßn Th∆°", "lat": 10.0452, "lng": 105.7469},
    {"name": "Nha Trang", "lat": 12.2388, "lng": 109.1967},
    {"name": "Hu·∫ø", "lat": 16.4637, "lng": 107.5909},
    {"name": "V≈©ng T√†u", "lat": 10.3460, "lng": 107.0843},
    {"name": "Phan Thi·∫øt", "lat": 10.9376, "lng": 108.1018},
    {"name": "Quy Nhon", "lat": 13.7765, "lng": 109.2237},
    {"name": "H·∫° Long", "lat": 20.9101, "lng": 107.1839},
    {"name": "Sapa", "lat": 22.3364, "lng": 103.8437},
    {"name": "ƒê√† L·∫°t", "lat": 11.9404, "lng": 108.4583},
    {"name": "H·ªôi An", "lat": 15.8801, "lng": 108.3380},
    {"name": "Ph√∫ Qu·ªëc", "lat": 10.2899, "lng": 103.9840},
    {"name": "M≈©i N√©", "lat": 10.9600, "lng": 108.2800},
    {"name": "Tam ƒê·∫£o", "lat": 21.4500, "lng": 105.6500},
    {"name": "C√°t B√†", "lat": 20.8000, "lng": 107.0167},
]

def main():
    """
    H√†m ch√≠nh ƒë·ªÉ t√¨m POI v√† scrape reviews cho 20 th√†nh ph·ªë n·ªïi ti·∫øng nh·∫•t ·ªü Vi·ªát Nam
    """
    print("\n" + "="*60)
    print("SCRAPER POI REVIEWS - Google Places API + Playwright")
    print("T·ª± ƒë·ªông ch·∫°y cho 20 th√†nh ph·ªë n·ªïi ti·∫øng nh·∫•t ·ªü Vi·ªát Nam")
    print("="*60)
    
    # H·ªèi s·ªë l∆∞·ª£ng POI t·ªëi ƒëa cho m·ªói th√†nh ph·ªë
    print("\nüìã Y√™u c·∫ßu: √çt nh·∫•t 65 POI m·ªói th√†nh ph·ªë, t·ªëi ƒëa 80 POI, m·ªói POI c√≥ > 100 reviews")
    max_results_input = input("S·ªë l∆∞·ª£ng POI t·ªëi ƒëa cho m·ªói th√†nh ph·ªë (m·∫∑c ƒë·ªãnh 80, nh·∫•n Enter ƒë·ªÉ d√πng m·∫∑c ƒë·ªãnh): ").strip()
    max_results_per_city = int(max_results_input) if max_results_input.isdigit() else 80
    min_results_per_city = 65  # Y√™u c·∫ßu t·ªëi thi·ªÉu 65 POI
    
    # H·ªèi c√≥ mu·ªën scrape reviews kh√¥ng
    scrape_reviews = input("\nB·∫°n c√≥ mu·ªën scrape reviews t·ª´ Google Maps kh√¥ng? (y/n, m·∫∑c ƒë·ªãnh: n): ").strip().lower()
    scrape_reviews = scrape_reviews == 'y'
    
    # T·∫°o th∆∞ m·ª•c reviews n·∫øu ch∆∞a c√≥
    os.makedirs('./reviews', exist_ok=True)
    
    # L∆∞u √Ω: M·ªói thread s·∫Ω t·∫°o browser ri√™ng v·ªõi Playwright
    # ƒêi·ªÅu n√†y gi√∫p tr√°nh conflict v√† cho ph√©p parallelization
    if scrape_reviews:
        print("\nüöÄ S·∫Ω s·ª≠ d·ª•ng Playwright v·ªõi parallelization (m·ªói thread c√≥ browser ri√™ng)")
        print("   ‚ö° Anti-detection: Random user agents, viewports, human-like behavior")
        print("   ‚ö° T·ªëc ƒë·ªô s·∫Ω nhanh h∆°n nh·ªù ch·∫°y song song nhi·ªÅu browser")
    
    # T·ªïng h·ª£p d·ªØ li·ªáu t·ª´ t·∫•t c·∫£ th√†nh ph·ªë
    all_reviews_data = []
    all_pois_summary = []
    
    # Ch·∫°y cho t·ª´ng th√†nh ph·ªë
    for city_idx, city in enumerate(VIETNAM_CITIES, 1):
        print("\n" + "‚ïê"*70)
        print(f"üèôÔ∏è  [{city_idx:2d}/{len(VIETNAM_CITIES)}] {city['name']}")
        print("‚ïê"*70)
        
        # T·∫°o query
        query = f"ƒê·ªãa ƒëi·ªÉm du l·ªãch v√† th·∫Øng c·∫£nh ·ªü {city['name']}"
        location = f"{city['lat']},{city['lng']}"
        
        print(f"   üîç Query: {query}")
        print(f"   üìç Location: ({city['lat']}, {city['lng']})")
        print(f"   üìã Y√™u c·∫ßu: {min_results_per_city}-{max_results_per_city} POI, m·ªói POI > 100 reviews")
        
        try:
            # T√¨m ki·∫øm POI v·ªõi pagination
            pois = search_pois_by_text(query, location, min_results=min_results_per_city, max_results=max_results_per_city)
            
            if not pois:
                print(f"\n   ‚ùå Kh√¥ng t√¨m th·∫•y POI n√†o ph√π h·ª£p")
                continue
            
            # Ki·ªÉm tra s·ªë l∆∞·ª£ng POI
            print(f"\n   {'‚îÄ'*66}")
            if len(pois) < min_results_per_city:
                print(f"   ‚ö†Ô∏è  C·∫£nh b√°o: {len(pois)}/{min_results_per_city} POI (thi·∫øu {min_results_per_city - len(pois)} POI)")
            else:
                print(f"   ‚úÖ T√¨m th·∫•y {len(pois)} POI (ƒë·∫°t y√™u c·∫ßu {min_results_per_city}-{max_results_per_city})")
            print(f"   {'‚îÄ'*66}")
            
            # Scrape reviews n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
            if scrape_reviews:
                num_threads = min(4, len(pois))
                print(f"\n   üìù Scraping reviews cho {len(pois)} POI")
                print(f"   ‚ö° Parallelization: {num_threads} threads")
                print(f"   {'‚îÄ'*66}")
                
                # Thread-safe lock cho vi·ªác append v√†o all_reviews_data
                data_lock = Lock()
                
                def scrape_poi_reviews(poi_data):
                    """Wrapper function ƒë·ªÉ scrape reviews cho m·ªôt POI v·ªõi Playwright"""
                    idx, poi = poi_data
                    browser = None
                    context = None
                    page = None
                    
                    try:
                        # Random delay tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu ƒë·ªÉ tr√°nh rate limiting
                        human_delay(0.5, 2.0)
                        
                        # T·∫°o browser ri√™ng cho m·ªói thread v·ªõi Playwright
                        with sync_playwright() as playwright:
                            browser, context, page = setup_playwright_browser(playwright)
                            
                            if not browser or not page:
                                print(f"      [{idx:3d}/{len(pois)}] ‚ö†Ô∏è  Kh√¥ng th·ªÉ t·∫°o browser: {poi['name'][:40]}")
                                return []
                            
                            print(f"      [{idx:3d}/{len(pois)}] üîÑ {poi['name'][:45]:<45} | {poi['user_rating_total']:>6} reviews")
                            
                            reviews = scrape_reviews_from_google_maps(poi['place_id'], page, max_reviews=150)
                            
                            # Tr·∫£ v·ªÅ c·∫£ s·ªë reviews ƒë·ªÉ x·ª≠ l√Ω sau
                            review_count = len(reviews) if reviews else 0
                            
                            # Ch·ªâ l∆∞u POI c√≥ s·ªë reviews > 80
                            if review_count > 80:
                                print(f"      [{idx:3d}/{len(pois)}] ‚úÖ {poi['name'][:45]:<45} | {review_count:>3d} reviews (ƒë·ªß ƒëi·ªÅu ki·ªán > 80)")
                                return [(poi['place_id'], review_count, review) for review in reviews]
                            elif review_count > 0:
                                print(f"      [{idx:3d}/{len(pois)}] ‚è≠Ô∏è  {poi['name'][:45]:<45} | {review_count:>3d} reviews (b·ªè qua, < 80)")
                                return [(poi['place_id'], review_count, None)]  # Tr·∫£ v·ªÅ v·ªõi review_count nh∆∞ng kh√¥ng c√≥ reviews
                            else:
                                print(f"      [{idx:3d}/{len(pois)}] ‚ö†Ô∏è  {poi['name'][:45]:<45} | 0 reviews")
                                return [(poi['place_id'], 0, None)]
                    except Exception as e:
                        error_msg = str(e)[:50]
                        if "Timeout" in error_msg:
                            print(f"      [{idx:3d}/{len(pois)}] ‚è±Ô∏è  {poi['name'][:45]:<45} | Timeout")
                        else:
                            print(f"      [{idx:3d}/{len(pois)}] ‚ùå {poi['name'][:45]:<45} | L·ªói: {error_msg}")
                        return []
                    finally:
                        # Cleanup v·ªõi delay ƒë·ªÉ tr√°nh ƒë√≥ng qu√° nhanh
                        try:
                            human_delay(0.5, 1.0)
                            if page:
                                page.close()
                            if context:
                                context.close()
                            if browser:
                                browser.close()
                        except:
                            pass
                
                # S·ª≠ d·ª•ng ThreadPoolExecutor ƒë·ªÉ parallelize
                max_workers = min(4, len(pois))  # T·ªëi ƒëa 4 threads ƒë·ªÉ tr√°nh qu√° t·∫£i
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    # Submit t·∫•t c·∫£ tasks
                    future_to_poi = {
                        executor.submit(scrape_poi_reviews, (idx, poi)): poi 
                        for idx, poi in enumerate(pois, 1)
                    }
                    
                    # X·ª≠ l√Ω k·∫øt qu·∫£ khi ho√†n th√†nh
                    poi_review_counts = {}  # ƒê·∫øm s·ªë reviews cho m·ªói POI
                    for future in as_completed(future_to_poi):
                        poi = future_to_poi[future]
                        try:
                            results = future.result()
                            if results:
                                # L·∫•y place_id v√† review_count t·ª´ k·∫øt qu·∫£
                                place_id = results[0][0] if results else None
                                review_count = results[0][1] if results and len(results[0]) > 1 else 0
                                
                                if place_id:
                                    poi_review_counts[place_id] = review_count
                                
                                # Thread-safe append (ch·ªâ append reviews n·∫øu > 80)
                                if review_count > 80:
                                    with data_lock:
                                        for result in results:
                                            if len(result) > 2 and result[2] is not None:  # C√≥ review text
                                                all_reviews_data.append({
                                                    'placeID': result[0],
                                                    'reviews': result[2]
                                                })
                        except Exception as e:
                            print(f"      ‚ùå L·ªói x·ª≠ l√Ω k·∫øt qu·∫£: {str(e)[:50]}")
                    
                    # C·∫≠p nh·∫≠t all_pois_summary: ch·ªâ gi·ªØ POI c√≥ > 80 reviews
                    filtered_pois_summary = []
                    for poi in pois:
                        place_id = poi['place_id']
                        review_count = poi_review_counts.get(place_id, 0)
                        if review_count > 80:
                            filtered_pois_summary.append({
                                'city': city['name'],
                                'place_id': place_id,
                                'name': poi['name'],
                                'user_rating_total': poi['user_rating_total']
                            })
                    
                    # C·∫≠p nh·∫≠t all_pois_summary v·ªõi filtered list (ch·ªâ POI c√≥ > 80 reviews)
                    with data_lock:
                        all_pois_summary.extend(filtered_pois_summary)
                    
                    # Th·ªëng k√™
                    total_pois = len(pois)
                    qualified_pois = len(filtered_pois_summary)
                    print(f"\n   ‚úÖ Ho√†n t·∫•t: {total_pois} POI ƒë√£ x·ª≠ l√Ω, {qualified_pois} POI c√≥ > 80 reviews (ƒë·ªß ƒëi·ªÅu ki·ªán)")
            else:
                # N·∫øu kh√¥ng scrape reviews, kh√¥ng l∆∞u POI n√†o v√†o summary
                # (v√¨ kh√¥ng bi·∫øt s·ªë reviews th·ª±c t·∫ø)
                print(f"\n   ‚ö†Ô∏è  Kh√¥ng scrape reviews, kh√¥ng l∆∞u POI v√†o summary")
            
        except Exception as e:
            print(f"‚ùå L·ªói khi x·ª≠ l√Ω {city['name']}: {e}")
            import traceback
            traceback.print_exc()
            continue  # Ti·∫øp t·ª•c v·ªõi th√†nh ph·ªë ti·∫øp theo
        
        # Ngh·ªâ gi·ªØa c√°c th√†nh ph·ªë
        if city_idx < len(VIETNAM_CITIES):
            print(f"\n   ‚è≥ ƒê·ª£i 3 gi√¢y tr∆∞·ªõc khi chuy·ªÉn sang th√†nh ph·ªë ti·∫øp theo...\n")
            time.sleep(3)
    
    # Kh√¥ng c·∫ßn ƒë√≥ng driver ·ªü ƒë√¢y v√¨ m·ªói thread ƒë√£ t·ª± ƒë√≥ng driver c·ªßa n√≥
    
    # L∆∞u summary POI
    summary_file = './reviews/pois_summary.csv'
    print(f"\n{'‚ïê'*70}")
    print(f"üíæ L∆ØU D·ªÆ LI·ªÜU")
    print(f"{'‚ïê'*70}")
    print(f"   üìÑ ƒêang l∆∞u summary POI...")
    try:
        with open(summary_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=['city', 'place_id', 'name', 'user_rating_total'])
            writer.writeheader()
            writer.writerows(all_pois_summary)
        print(f"   ‚úÖ ƒê√£ l∆∞u {len(all_pois_summary)} POI ‚Üí {summary_file}")
    except Exception as e:
        print(f"   ‚ùå L·ªói khi l∆∞u summary: {e}")
    
    # L∆∞u reviews v√†o CSV (n·∫øu c√≥)
    if all_reviews_data:
        output_file = './reviews/all_reviews.csv'
        print(f"   üìÑ ƒêang l∆∞u {len(all_reviews_data):,} reviews...")
        
        try:
            # Ki·ªÉm tra file ƒë√£ t·ªìn t·∫°i ch∆∞a ƒë·ªÉ append ho·∫∑c t·∫°o m·ªõi
            file_exists = os.path.exists(output_file)
            with open(output_file, 'a' if file_exists else 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=['placeID', 'reviews'])
                if not file_exists:
                    writer.writeheader()
                writer.writerows(all_reviews_data)
            
            print(f"   ‚úÖ ƒê√£ l∆∞u {len(all_reviews_data):,} reviews ‚Üí {output_file}")
            
            # Th·ªëng k√™ theo th√†nh ph·ªë
            city_stats = {}
            for poi in all_pois_summary:
                city = poi['city']
                if city not in city_stats:
                    city_stats[city] = {'pois': 0, 'reviews': 0}
                city_stats[city]['pois'] += 1
            
            # ƒê·∫øm reviews theo placeID v√† map v·ªÅ city
            poi_to_city = {poi['place_id']: poi['city'] for poi in all_pois_summary}
            for row in all_reviews_data:
                place_id = row['placeID']
                if place_id in poi_to_city:
                    city = poi_to_city[place_id]
                    city_stats[city]['reviews'] += 1
            
            print(f"\n   üìä Th·ªëng k√™ theo th√†nh ph·ªë:")
            print(f"   {'‚îÄ'*66}")
            for city, stats in sorted(city_stats.items()):
                print(f"   {city:30s} | {stats['pois']:3d} POI | {stats['reviews']:6,} reviews")
            
        except Exception as e:
            print(f"   ‚ùå L·ªói khi l∆∞u file CSV: {e}")
    else:
        print(f"   ‚ö†Ô∏è  Kh√¥ng c√≥ reviews n√†o ƒë∆∞·ª£c scrape")
    
    # T·ªïng k·∫øt
    print(f"\n{'‚ïê'*70}")
    print(f"‚úÖ HO√ÄN T·∫§T!")
    print(f"{'‚ïê'*70}")
    print(f"   üèôÔ∏è  Th√†nh ph·ªë ƒë√£ x·ª≠ l√Ω: {len(VIETNAM_CITIES)}")
    print(f"   üìç T·ªïng s·ªë POI: {len(all_pois_summary):,}")
    if all_reviews_data:
        print(f"   üìù T·ªïng s·ªë reviews: {len(all_reviews_data):,}")
    print(f"   üíæ File summary: {summary_file}")
    if all_reviews_data:
        print(f"   üíæ File reviews: ./reviews/all_reviews.csv")
    print(f"{'‚ïê'*70}\n")

if __name__ == "__main__":
    main()

